{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc84c0b4",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on IMDB Rating\n",
    "Implemented using RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cec45dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchtext\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datasets\n",
    "import re\n",
    "from collections import Counter, OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c1181a",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c318352",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load test and train data\n",
    "train_data, test_data = datasets.load_dataset('imdb', split=['train','test'])\n",
    "\n",
    "#Split test data into train (20k) and validate (5k)\n",
    "from torch.utils.data.dataset import random_split\n",
    "torch.manual_seed(1)\n",
    "train_data, valid_data = random_split(list(train_data),[20000,5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b27bfc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    # Remove HTML tags\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    # Extract emoticons\n",
    "    emoticons = re.findall(r'(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
    "    # Eliminate excessive whitespace and convert text to lowercase\n",
    "    text = re.sub(r'[\\W]+', ' ', text.lower())\n",
    "    # Append emoticons at the end, removing the \"nose\" for standardization\n",
    "    text = text + ' ' + ' '.join(emoticons).replace('-', '')\n",
    "    #Split by white space\n",
    "    tokenized = text.split()\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c5965c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tokens 69006\n"
     ]
    }
   ],
   "source": [
    "#How many unique tokens are in the text corpus?\n",
    "token_counts = Counter()\n",
    "for review in train_data:\n",
    "    text = review['text']\n",
    "    tokens = tokenizer(text)\n",
    "    token_counts.update(tokens)\n",
    "print('number of tokens', len(token_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a726f49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11558, 26, 736]\n",
      "[11558, 26, 736, 2152]\n"
     ]
    }
   ],
   "source": [
    "#Map each token to a unique integer. In reverse frequency order. 0 and 1 placeholders\n",
    "#Sort counter in reverse frequency order\n",
    "sorted_dict = sorted(\n",
    "    token_counts.items(), key=lambda x:x[1], reverse=True\n",
    ")\n",
    "ordered_dict = OrderedDict(sorted_dict)\n",
    "\n",
    "#Word_index contains word:index pairs\n",
    "word_index = {}\n",
    "counter = 2\n",
    "for word, freq in ordered_dict.items():\n",
    "    word_index[word] = counter\n",
    "    counter += 1\n",
    "\n",
    "#0 reserverd for padding. 1 reserved for unknown words\n",
    "word_index['<pad>'] = 0\n",
    "word_index['<unk>'] = 1\n",
    "\n",
    "#Demonstrate encoding scheme works\n",
    "def word_index_conversion(text):\n",
    "    encoding = []\n",
    "    tokens = tokenizer(text)\n",
    "    for token in tokens:\n",
    "        encoding.append(word_index.get(token,1))\n",
    "    return encoding\n",
    "\n",
    "#Testing\n",
    "print(word_index_conversion(\"Roses are red\"))\n",
    "print(word_index_conversion(\"roSes ARE reD :)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "57718664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataloader(batch):\n",
    "    label_list, text_list, lengths = [], [], []\n",
    "    for review in batch:\n",
    "        text = review['text']\n",
    "        label = review['label']\n",
    "        label_list.append(label)\n",
    "        processed_text = torch.tensor(word_index_conversion(text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        lengths.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list)\n",
    "    lengths = torch.tensor(lengths)\n",
    "    #Ensure all sequence in minibatch have same length to store efficiently as tensor\n",
    "    padded_text_list = nn.utils.rnn.pad_sequence(text_list, batch_first=True)\n",
    "    return padded_text_list, label_list, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1353bbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load a small sample with batchsize of 4\n",
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(train_data,batch_size=4,shuffle=False, collate_fn=build_dataloader)\n",
    "text_batch, label_batch, length_batch = next(iter(dataloader))\n",
    "#Length of text_batch is maximum in the minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "946f517d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide into batches of size 32\n",
    "batch_size = 32\n",
    "train_dl = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=build_dataloader)\n",
    "valid_dl = DataLoader(valid_data, batch_size=batch_size, shuffle=True, collate_fn=build_dataloader)\n",
    "test_dl = DataLoader(test_data, batch_size=batch_size, shuffle=True, collate_fn=build_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5502e7",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction\n",
    "One way to encode the index is via one hot encoding. Results in sparse feature vectors \\\n",
    "Suffer from curse of dimensionality \\\n",
    "A better approach is to map each word to a vector of fixed size with real-valued elements \\\n",
    "-> Advantage: Reduction in dimensionality of the feature space \\\n",
    "-> Extraction of salient features since the embedding layer in an NN can be optimized \\\n",
    "Let n be the number of unique words \\\n",
    "Embedding matrix is of size (n+2) x embedding_dim. Reserve 2 spots for \\<unknown\\> and \\<pad\\> \\\n",
    "Given integer index i, simply look up the row at index i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "250c8183",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#Sample training data\u001b[39;00m\n\u001b[1;32m      5\u001b[0m text_encoded_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mLongTensor([word_index_conversion(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRoses are red\u001b[39m\u001b[38;5;124m\"\u001b[39m), \n\u001b[1;32m      6\u001b[0m                                       word_index_conversion(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mViolets are blue\u001b[39m\u001b[38;5;124m\"\u001b[39m)])\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_encoded_input\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/quant/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/quant/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/quant/lib/python3.10/site-packages/torch/nn/modules/sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/quant/lib/python3.10/site-packages/torch/nn/functional.py:2264\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2258\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2259\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2260\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2261\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2262\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2263\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "embedding = nn.Embedding(num_embeddings=100, \n",
    "                         embedding_dim=3, #Dim of embedding space\n",
    "                         padding_idx=0) #Which index indicates padding. Doesn't contribute to gradient update\n",
    "#Sample training data\n",
    "text_encoded_input = torch.LongTensor([word_index_conversion(\"Roses are red\"), \n",
    "                                      word_index_conversion(\"Violets are blue\")])\n",
    "print(embedding(text_encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac46948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000f2435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f649662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0390de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
